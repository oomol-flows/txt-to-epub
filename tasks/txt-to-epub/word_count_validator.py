import re
import logging
from typing import Dict, List, Tuple, Any
from .data_structures import Volume, Chapter, Section

# Configure logging
logger = logging.getLogger(__name__)


class WordCountValidator:
    """Word count validator for comparing text quantity before and after conversion"""
    
    def __init__(self):
        self.original_stats = {}
        self.converted_stats = {}
    
    def clean_text_for_counting(self, text: str) -> str:
        """
        Clean text for counting, remove extra whitespace and punctuation
        
        :param text: Original text
        :return: Cleaned text
        """
        if not text:
            return ""
        
        # Remove extra whitespace (spaces, tabs, newlines, etc.)
        cleaned = re.sub(r'\s+', '', text)
        
        # Remove common punctuation and special characters (but keep Chinese characters)
        # Only remove obvious separators, keep potentially meaningful punctuation
        cleaned = re.sub(r'[ã€€\u3000]+', '', cleaned)  # Remove Chinese spaces
        
        return cleaned
    
    def count_characters(self, text: str) -> Dict[str, int]:
        """
        Count characters in text
        
        :param text: Text content
        :return: Character statistics dictionary
        """
        cleaned_text = self.clean_text_for_counting(text)
        
        # Count Chinese characters (including Chinese punctuation)
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff\u3400-\u4dbf]', cleaned_text))
        
        # Count English letters and numbers
        english_chars = len(re.findall(r'[a-zA-Z0-9]', cleaned_text))
        
        # Count punctuation - use Unicode ranges to avoid encoding issues
        chinese_punctuation = len(re.findall(r'[\u3000-\u303f\uff00-\uffef]', cleaned_text))  # Chinese punctuation
        english_punctuation = len(re.findall(r'[.,!?;:()\[\]<>"\'\\-]', cleaned_text))  # English punctuation
        punctuation = chinese_punctuation + english_punctuation
        
        # Total characters (excluding whitespace)
        total_chars = len(cleaned_text)
        
        # Original text total length (including whitespace)
        original_length = len(text) if text else 0
        
        return {
            'chinese_chars': chinese_chars,
            'english_chars': english_chars,
            'punctuation': punctuation,
            'total_chars': total_chars,
            'original_length': original_length
        }
    
    def analyze_original_content(self, content: str) -> Dict[str, int]:
        """
        Analyze text statistics of original txt file
        
        :param content: Original text content
        :return: Statistics result dictionary
        """
        stats = self.count_characters(content)
        self.original_stats = stats
        
        logger.info(f"Original file statistics:")
        logger.info(f"  - Chinese characters: {stats['chinese_chars']}")
        logger.info(f"  - English characters: {stats['english_chars']}")
        logger.info(f"  - Punctuation: {stats['punctuation']}")
        logger.info(f"  - Total characters (no whitespace): {stats['total_chars']}")
        logger.info(f"  - Original length (with whitespace): {stats['original_length']}")
        
        return stats
    
    def extract_content_from_volumes(self, volumes: List[Volume]) -> str:
        """
        Extract all text content from converted volume structure
        
        :param volumes: Volume list
        :return: Extracted all text content
        """
        all_content = []
        
        for volume in volumes:
            # æ·»åŠ å·æ ‡é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
            if volume.title:
                all_content.append(volume.title)
            
            for chapter in volume.chapters:
                # æ·»åŠ ç« èŠ‚æ ‡é¢˜
                if chapter.title:
                    all_content.append(chapter.title)
                
                # æ·»åŠ ç« èŠ‚å†…å®¹
                if chapter.content:
                    all_content.append(chapter.content)
                
                # æ·»åŠ èŠ‚çš„å†…å®¹
                for section in chapter.sections:
                    if section.title:
                        all_content.append(section.title)
                    if section.content:
                        all_content.append(section.content)
        
        return '\n'.join(all_content)
    
    def analyze_converted_content(self, volumes: List[Volume]) -> Dict[str, int]:
        """
        åˆ†æè½¬æ¢åepubå†…å®¹çš„æ–‡å­—ç»Ÿè®¡
        
        :param volumes: è½¬æ¢åçš„å·ç»“æ„
        :return: ç»Ÿè®¡ç»“æœå­—å…¸
        """
        extracted_content = self.extract_content_from_volumes(volumes)
        stats = self.count_characters(extracted_content)
        self.converted_stats = stats
        
        logger.info(f"è½¬æ¢åå†…å®¹ç»Ÿè®¡:")
        logger.info(f"  - Chinese characters: {stats['chinese_chars']}")
        logger.info(f"  - English characters: {stats['english_chars']}")
        logger.info(f"  - Punctuation: {stats['punctuation']}")
        logger.info(f"  - Total characters (no whitespace): {stats['total_chars']}")
        logger.info(f"  - Original length (with whitespace): {stats['original_length']}")
        
        return stats
    
    def analyze_content_changes(self) -> Dict[str, str]:
        """
        åˆ†æå†…å®¹å˜åŒ–çš„åŸå› ï¼Œæä¾›è¯¦ç»†çš„è§£é‡Š
        
        :return: åŒ…å«å˜åŒ–åŸå› åˆ†æçš„å­—å…¸
        """
        if not self.original_stats or not self.converted_stats:
            return {"error": "ç¼ºå°‘ç»Ÿè®¡æ•°æ®"}
        
        analysis = {}
        diffs = {
            'chinese_chars': self.converted_stats['chinese_chars'] - self.original_stats['chinese_chars'],
            'english_chars': self.converted_stats['english_chars'] - self.original_stats['english_chars'],
            'punctuation': self.converted_stats['punctuation'] - self.original_stats['punctuation'],
            'total_chars': self.converted_stats['total_chars'] - self.original_stats['total_chars']
        }
        
        # åˆ†æä¸­æ–‡å­—ç¬¦å˜åŒ–
        if abs(diffs['chinese_chars']) <= self.original_stats['chinese_chars'] * 0.005:  # 0.5%ä»¥å†…
            analysis['chinese_reason'] = "ä¸­æ–‡å­—ç¬¦æ•°é‡åŸºæœ¬ä¿æŒä¸€è‡´ï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚"
            analysis['chinese_concern'] = "æ— éœ€æ‹…å¿ƒ"
        elif diffs['chinese_chars'] > 0:
            analysis['chinese_reason'] = "ä¸­æ–‡å­—ç¬¦æ•°é‡è½»å¾®å¢åŠ ï¼Œå¯èƒ½åŸå› ï¼š1) è§£æå™¨è‡ªåŠ¨æ·»åŠ äº†ç« èŠ‚æ ‡é¢˜ï¼›2) è¡¥å……äº†ç¼ºå¤±çš„æ ‡ç‚¹ç¬¦å·ï¼›3) æ ¼å¼åŒ–è¿‡ç¨‹ä¸­çš„æ­£å¸¸å¤„ç†ã€‚"
            analysis['chinese_concern'] = "æ— éœ€æ‹…å¿ƒï¼Œè¿™é€šå¸¸æ˜¯æ­£å¸¸çš„å¤„ç†ç»“æœ"
        elif diffs['chinese_chars'] < 0:
            loss_rate = abs(diffs['chinese_chars']) / self.original_stats['chinese_chars'] * 100
            if loss_rate <= 1.0:
                analysis['chinese_reason'] = "ä¸­æ–‡å­—ç¬¦æ•°é‡è½»å¾®å‡å°‘ï¼Œå¯èƒ½åŸå› ï¼š1) ç§»é™¤äº†é‡å¤çš„ç©ºç™½å­—ç¬¦ï¼›2) ç»Ÿä¸€äº†æ ‡ç‚¹ç¬¦å·æ ¼å¼ï¼›3) æ¸…ç†äº†æ— æ•ˆå­—ç¬¦ã€‚"
                analysis['chinese_concern'] = "åŸºæœ¬æ— éœ€æ‹…å¿ƒï¼Œä¸¢å¤±ç‡åœ¨å¯æ¥å—èŒƒå›´å†…"
            else:
                analysis['chinese_reason'] = "ä¸­æ–‡å­—ç¬¦æ•°é‡æ˜æ˜¾å‡å°‘ï¼Œå¯èƒ½åŸå› ï¼š1) æ–‡ä»¶ç¼–ç é—®é¢˜å¯¼è‡´éƒ¨åˆ†å­—ç¬¦ä¸¢å¤±ï¼›2) è§£æè¿‡ç¨‹ä¸­è·³è¿‡äº†æŸäº›å†…å®¹ï¼›3) æ ¼å¼è¯†åˆ«é”™è¯¯ã€‚"
                analysis['chinese_concern'] = "éœ€è¦å…³æ³¨ï¼Œå»ºè®®æ£€æŸ¥åŸæ–‡ä»¶ç¼–ç å’Œå†…å®¹ç»“æ„"
        
        # åˆ†æè‹±æ–‡å­—ç¬¦å˜åŒ–
        if abs(diffs['english_chars']) <= max(self.original_stats['english_chars'] * 0.02, 10):  # 2%æˆ–10ä¸ªå­—ç¬¦ä»¥å†…
            analysis['english_reason'] = "è‹±æ–‡å­—ç¬¦æ•°é‡å˜åŒ–å¾ˆå°ï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚å¯èƒ½æ˜¯æ ¼å¼åŒ–æ—¶ç©ºæ ¼å¤„ç†çš„å·®å¼‚ã€‚"
            analysis['english_concern'] = "æ— éœ€æ‹…å¿ƒ"
        elif diffs['english_chars'] > 0:
            analysis['english_reason'] = "è‹±æ–‡å­—ç¬¦æ•°é‡å¢åŠ ï¼Œå¯èƒ½åŸå› ï¼š1) è§£æå™¨æ·»åŠ äº†HTMLæ ‡ç­¾ä¸­çš„è‹±æ–‡ï¼›2) è‡ªåŠ¨ç”Ÿæˆçš„ç« èŠ‚å¯¼èˆªï¼›3) æ ¼å¼åŒ–æ ‡è¯†ç¬¦ã€‚"
            analysis['english_concern'] = "æ— éœ€æ‹…å¿ƒï¼Œè¿™é€šå¸¸æ˜¯EPUBæ ¼å¼çš„æ­£å¸¸éœ€æ±‚"
        else:
            loss_rate = abs(diffs['english_chars']) / max(self.original_stats['english_chars'], 1) * 100
            if loss_rate <= 5.0:
                analysis['english_reason'] = "è‹±æ–‡å­—ç¬¦æ•°é‡å‡å°‘ï¼Œå¯èƒ½åŸå› ï¼š1) ç§»é™¤äº†å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦ï¼›2) ç»Ÿä¸€äº†å­—ç¬¦ç¼–ç ï¼›3) æ¸…ç†äº†æ ¼å¼æ§åˆ¶ç¬¦ã€‚"
                analysis['english_concern'] = "åŸºæœ¬æ— éœ€æ‹…å¿ƒ"
            else:
                analysis['english_reason'] = "è‹±æ–‡å­—ç¬¦æ•°é‡æ˜æ˜¾å‡å°‘ï¼Œå¯èƒ½åŸå› ï¼š1) ç¼–ç è½¬æ¢é—®é¢˜ï¼›2) è§£ææ—¶é—æ¼äº†è‹±æ–‡å†…å®¹ï¼›3) æ–‡ä»¶ç»“æ„è¯†åˆ«é”™è¯¯ã€‚"
                analysis['english_concern'] = "éœ€è¦å…³æ³¨ï¼Œå»ºè®®æ£€æŸ¥è‹±æ–‡å†…å®¹æ˜¯å¦å®Œæ•´"
        
        # åˆ†ææ ‡ç‚¹ç¬¦å·å˜åŒ–
        if abs(diffs['punctuation']) <= max(self.original_stats['punctuation'] * 0.1, 5):  # 10%æˆ–5ä¸ªä»¥å†…
            analysis['punctuation_reason'] = "æ ‡ç‚¹ç¬¦å·æ•°é‡å˜åŒ–å¾ˆå°ï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚"
            analysis['punctuation_concern'] = "æ— éœ€æ‹…å¿ƒ"
        elif diffs['punctuation'] > 0:
            analysis['punctuation_reason'] = "æ ‡ç‚¹ç¬¦å·æ•°é‡å¢åŠ ï¼Œå¯èƒ½åŸå› ï¼š1) ç»Ÿä¸€æ ‡ç‚¹ç¬¦å·æ ¼å¼ï¼ˆå¦‚åŠè§’è½¬å…¨è§’ï¼‰ï¼›2) æ·»åŠ äº†EPUBæ ¼å¼éœ€è¦çš„æ ‡ç‚¹ï¼›3) è¡¥å……äº†è¯­æ³•æ ‡ç‚¹ã€‚"
            analysis['punctuation_concern'] = "æ— éœ€æ‹…å¿ƒï¼Œè¿™æœ‰åŠ©äºé˜…è¯»ä½“éªŒ"
        else:
            analysis['punctuation_reason'] = "æ ‡ç‚¹ç¬¦å·æ•°é‡å‡å°‘ï¼Œå¯èƒ½åŸå› ï¼š1) ç§»é™¤äº†é‡å¤æˆ–æ— æ„ä¹‰çš„æ ‡ç‚¹ï¼›2) ç»Ÿä¸€äº†æ ‡ç‚¹ç¬¦å·æ ¼å¼ï¼›3) æ¸…ç†äº†æ ¼å¼æ§åˆ¶ç¬¦ã€‚"
            analysis['punctuation_concern'] = "é€šå¸¸æ— éœ€æ‹…å¿ƒï¼Œé™¤éå‘ç°é˜…è¯»æ—¶æ ‡ç‚¹æ˜æ˜¾ç¼ºå¤±"
        
        # åˆ†ææ€»ä½“å˜åŒ–
        total_loss_rate = (self.original_stats['total_chars'] - self.converted_stats['total_chars']) / self.original_stats['total_chars'] * 100
        if total_loss_rate <= 0.5:
            analysis['overall_reason'] = "æ€»ä½“å­—ç¬¦æ•°é‡ä¿æŒç¨³å®šï¼Œè½¬æ¢è´¨é‡è‰¯å¥½ã€‚"
            analysis['overall_concern'] = "å†…å®¹å®Œæ•´æ€§ä¼˜ç§€ï¼Œå¯ä»¥æ”¾å¿ƒä½¿ç”¨"
        elif total_loss_rate <= 1.0:
            analysis['overall_reason'] = "æ€»ä½“å­—ç¬¦æ•°é‡ç•¥æœ‰å‡å°‘ï¼Œä¸»è¦æ˜¯æ ¼å¼æ¸…ç†å’Œæ ‡å‡†åŒ–çš„ç»“æœã€‚"
            analysis['overall_concern'] = "å†…å®¹å®Œæ•´æ€§è‰¯å¥½ï¼Œæ­£å¸¸çš„å¤„ç†ç»“æœ"
        elif total_loss_rate <= 2.0:
            analysis['overall_reason'] = "æ€»ä½“å­—ç¬¦æ•°é‡æœ‰æ‰€å‡å°‘ï¼Œå¯èƒ½æ˜¯ç§»é™¤äº†å†—ä½™çš„æ ¼å¼å­—ç¬¦å’Œç©ºç™½ã€‚"
            analysis['overall_concern'] = "éœ€è¦é€‚åº¦å…³æ³¨ï¼Œå»ºè®®æŠ½æŸ¥é‡è¦ç« èŠ‚å†…å®¹"
        else:
            analysis['overall_reason'] = "æ€»ä½“å­—ç¬¦æ•°é‡æ˜æ˜¾å‡å°‘ï¼Œå¯èƒ½å­˜åœ¨å†…å®¹è§£ææˆ–è½¬æ¢é—®é¢˜ã€‚"
            analysis['overall_concern'] = "éœ€è¦é‡ç‚¹å…³æ³¨ï¼Œå¼ºçƒˆå»ºè®®æ£€æŸ¥è½¬æ¢ç»“æœ"
        
        return analysis
    
    def compare_content(self) -> Tuple[bool, Dict[str, Any]]:
        """
        å¯¹æ¯”åŸå§‹å†…å®¹å’Œè½¬æ¢åå†…å®¹çš„å·®å¼‚
        
        :return: (æ˜¯å¦é€šè¿‡éªŒè¯, å¯¹æ¯”ç»“æœè¯¦æƒ…)
        """
        if not self.original_stats or not self.converted_stats:
            return False, {"error": "ç¼ºå°‘ç»Ÿè®¡æ•°æ®ï¼Œè¯·å…ˆåˆ†æåŸå§‹å†…å®¹å’Œè½¬æ¢åå†…å®¹"}
        
        # è®¡ç®—å·®å¼‚
        chinese_diff = self.converted_stats['chinese_chars'] - self.original_stats['chinese_chars']
        english_diff = self.converted_stats['english_chars'] - self.original_stats['english_chars']
        punctuation_diff = self.converted_stats['punctuation'] - self.original_stats['punctuation']
        total_diff = self.converted_stats['total_chars'] - self.original_stats['total_chars']
        
        # è®¡ç®—ä¸¢å¤±ç‡
        def calc_loss_rate(original, converted):
            if original == 0:
                return 0.0
            return (original - converted) / original * 100
        
        chinese_loss_rate = calc_loss_rate(self.original_stats['chinese_chars'], self.converted_stats['chinese_chars'])
        english_loss_rate = calc_loss_rate(self.original_stats['english_chars'], self.converted_stats['english_chars'])
        total_loss_rate = calc_loss_rate(self.original_stats['total_chars'], self.converted_stats['total_chars'])
        
        # éªŒè¯æ ‡å‡†ï¼šå…è®¸å°‘é‡å­—ç¬¦å·®å¼‚ï¼ˆè€ƒè™‘åˆ°è§£æå’Œæ ¼å¼åŒ–çš„å½±å“ï¼‰
        # ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ç‡ä¸è¶…è¿‡1%ï¼Œè‹±æ–‡å­—ç¬¦ä¸¢å¤±ç‡ä¸è¶…è¿‡2%ï¼Œæ€»ä½“ä¸¢å¤±ç‡ä¸è¶…è¿‡1%
        is_valid = (
            chinese_loss_rate <= 1.0 and 
            english_loss_rate <= 2.0 and 
            total_loss_rate <= 1.0 and
            chinese_diff >= -self.original_stats['chinese_chars'] * 0.01  # ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ä¸è¶…è¿‡1%
        )
        
        result = {
            "is_valid": is_valid,
            "original_stats": self.original_stats.copy(),
            "converted_stats": self.converted_stats.copy(),
            "differences": {
                "chinese_chars": chinese_diff,
                "english_chars": english_diff,
                "punctuation": punctuation_diff,
                "total_chars": total_diff
            },
            "loss_rates": {
                "chinese_chars": chinese_loss_rate,
                "english_chars": english_loss_rate,
                "total_chars": total_loss_rate
            }
        }
        
        # è®°å½•éªŒè¯ç»“æœ
        if is_valid:
            logger.info("âœ… å†…å®¹éªŒè¯é€šè¿‡ï¼è½¬æ¢åå†…å®¹å®Œæ•´æ€§è‰¯å¥½")
        else:
            logger.warning("âš ï¸ å†…å®¹éªŒè¯å¤±è´¥ï¼å¯èƒ½å­˜åœ¨å†…å®¹ä¸¢å¤±")
            if chinese_loss_rate > 1.0:
                logger.warning(f"ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ç‡è¿‡é«˜: {chinese_loss_rate:.2f}%")
            if english_loss_rate > 2.0:
                logger.warning(f"è‹±æ–‡å­—ç¬¦ä¸¢å¤±ç‡è¿‡é«˜: {english_loss_rate:.2f}%")
            if total_loss_rate > 1.0:
                logger.warning(f"æ€»ä½“å­—ç¬¦ä¸¢å¤±ç‡è¿‡é«˜: {total_loss_rate:.2f}%")
        
        logger.info(f"å­—ç¬¦å·®å¼‚è¯¦æƒ…:")
        logger.info(f"  - ä¸­æ–‡å­—ç¬¦å·®å¼‚: {chinese_diff} (ä¸¢å¤±ç‡: {chinese_loss_rate:.2f}%)")
        logger.info(f"  - è‹±æ–‡å­—ç¬¦å·®å¼‚: {english_diff} (ä¸¢å¤±ç‡: {english_loss_rate:.2f}%)")
        logger.info(f"  - æ ‡ç‚¹ç¬¦å·å·®å¼‚: {punctuation_diff}")
        logger.info(f"  - æ€»å­—ç¬¦å·®å¼‚: {total_diff} (ä¸¢å¤±ç‡: {total_loss_rate:.2f}%)")
        
        return is_valid, result
        """
        å¯¹æ¯”åŸå§‹å†…å®¹å’Œè½¬æ¢åå†…å®¹çš„å·®å¼‚
        
        :return: (æ˜¯å¦é€šè¿‡éªŒè¯, å¯¹æ¯”ç»“æœè¯¦æƒ…)
        """
        if not self.original_stats or not self.converted_stats:
            return False, {"error": "ç¼ºå°‘ç»Ÿè®¡æ•°æ®ï¼Œè¯·å…ˆåˆ†æåŸå§‹å†…å®¹å’Œè½¬æ¢åå†…å®¹"}
        
        # è®¡ç®—å·®å¼‚
        chinese_diff = self.converted_stats['chinese_chars'] - self.original_stats['chinese_chars']
        english_diff = self.converted_stats['english_chars'] - self.original_stats['english_chars']
        punctuation_diff = self.converted_stats['punctuation'] - self.original_stats['punctuation']
        total_diff = self.converted_stats['total_chars'] - self.original_stats['total_chars']
        
        # è®¡ç®—ä¸¢å¤±ç‡
        def calc_loss_rate(original, converted):
            if original == 0:
                return 0.0
            return (original - converted) / original * 100
        
        chinese_loss_rate = calc_loss_rate(self.original_stats['chinese_chars'], self.converted_stats['chinese_chars'])
        english_loss_rate = calc_loss_rate(self.original_stats['english_chars'], self.converted_stats['english_chars'])
        total_loss_rate = calc_loss_rate(self.original_stats['total_chars'], self.converted_stats['total_chars'])
        
        # éªŒè¯æ ‡å‡†ï¼šå…è®¸å°‘é‡å­—ç¬¦å·®å¼‚ï¼ˆè€ƒè™‘åˆ°è§£æå’Œæ ¼å¼åŒ–çš„å½±å“ï¼‰
        # ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ç‡ä¸è¶…è¿‡1%ï¼Œè‹±æ–‡å­—ç¬¦ä¸¢å¤±ç‡ä¸è¶…è¿‡2%ï¼Œæ€»ä½“ä¸¢å¤±ç‡ä¸è¶…è¿‡1%
        is_valid = (
            chinese_loss_rate <= 1.0 and 
            english_loss_rate <= 2.0 and 
            total_loss_rate <= 1.0 and
            chinese_diff >= -self.original_stats['chinese_chars'] * 0.01  # ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ä¸è¶…è¿‡1%
        )
        
        result = {
            "is_valid": is_valid,
            "original_stats": self.original_stats.copy(),
            "converted_stats": self.converted_stats.copy(),
            "differences": {
                "chinese_chars": chinese_diff,
                "english_chars": english_diff,
                "punctuation": punctuation_diff,
                "total_chars": total_diff
            },
            "loss_rates": {
                "chinese_chars": chinese_loss_rate,
                "english_chars": english_loss_rate,
                "total_chars": total_loss_rate
            }
        }
        
        # è®°å½•éªŒè¯ç»“æœ
        if is_valid:
            logger.info("âœ… å†…å®¹éªŒè¯é€šè¿‡ï¼è½¬æ¢åå†…å®¹å®Œæ•´æ€§è‰¯å¥½")
        else:
            logger.warning("âš ï¸ å†…å®¹éªŒè¯å¤±è´¥ï¼å¯èƒ½å­˜åœ¨å†…å®¹ä¸¢å¤±")
            if chinese_loss_rate > 1.0:
                logger.warning(f"ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ç‡è¿‡é«˜: {chinese_loss_rate:.2f}%")
            if english_loss_rate > 2.0:
                logger.warning(f"è‹±æ–‡å­—ç¬¦ä¸¢å¤±ç‡è¿‡é«˜: {english_loss_rate:.2f}%")
            if total_loss_rate > 1.0:
                logger.warning(f"æ€»ä½“å­—ç¬¦ä¸¢å¤±ç‡è¿‡é«˜: {total_loss_rate:.2f}%")
        
        logger.info(f"å­—ç¬¦å·®å¼‚è¯¦æƒ…:")
        logger.info(f"  - ä¸­æ–‡å­—ç¬¦å·®å¼‚: {chinese_diff} (ä¸¢å¤±ç‡: {chinese_loss_rate:.2f}%)")
        logger.info(f"  - è‹±æ–‡å­—ç¬¦å·®å¼‚: {english_diff} (ä¸¢å¤±ç‡: {english_loss_rate:.2f}%)")
        logger.info(f"  - æ ‡ç‚¹ç¬¦å·å·®å¼‚: {punctuation_diff}")
        logger.info(f"  - æ€»å­—ç¬¦å·®å¼‚: {total_diff} (ä¸¢å¤±ç‡: {total_loss_rate:.2f}%)")
        
        return is_valid, result
    
    def generate_validation_report(self) -> str:
        """
        ç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰
        
        :return: Markdownæ ¼å¼çš„éªŒè¯æŠ¥å‘Šæ–‡æœ¬
        """
        is_valid, result = self.compare_content()
        analysis = self.analyze_content_changes()
        
        report = []
        report.append("# TXTè½¬EPUBæ–‡å­—å†…å®¹å®Œæ•´æ€§éªŒè¯æŠ¥å‘Š")
        report.append("")
        
        # ä½¿ç”¨è¡¨æ ¼å±•ç¤ºè½¬æ¢å‰åå¯¹æ¯”
        report.append("## ï¿½ è½¬æ¢å‰åå¯¹æ¯”")
        report.append("")
        report.append("| é¡¹ç›® | è½¬æ¢å‰ | è½¬æ¢å | å·®å¼‚ | ä¸¢å¤±ç‡ |")
        report.append("|------|--------|--------|------|--------|")
        
        diffs = result['differences']
        rates = result['loss_rates']
        
        def format_diff(diff):
            if diff > 0:
                return f"+{diff:,}"
            elif diff < 0:
                return f"{diff:,}"
            else:
                return "0"
        
        def format_loss_rate(rate):
            if rate > 0:
                return f"{rate:.2f}%"
            else:
                return "0%"
        
        # æ·»åŠ è¡¨æ ¼è¡Œ
        report.append(f"| ä¸­æ–‡å­—ç¬¦ | {result['original_stats']['chinese_chars']:,} | {result['converted_stats']['chinese_chars']:,} | {format_diff(diffs['chinese_chars'])} | {format_loss_rate(rates['chinese_chars'])} |")
        report.append(f"| è‹±æ–‡å­—ç¬¦ | {result['original_stats']['english_chars']:,} | {result['converted_stats']['english_chars']:,} | {format_diff(diffs['english_chars'])} | {format_loss_rate(rates['english_chars'])} |")
        report.append(f"| æ ‡ç‚¹ç¬¦å· | {result['original_stats']['punctuation']:,} | {result['converted_stats']['punctuation']:,} | {format_diff(diffs['punctuation'])} | - |")
        report.append(f"| **æ€»å­—ç¬¦æ•°** | **{result['original_stats']['total_chars']:,}** | **{result['converted_stats']['total_chars']:,}** | **{format_diff(diffs['total_chars'])}** | **{format_loss_rate(rates['total_chars'])}** |")
        report.append("")
        
        # éªŒè¯ç»“æœ
        if is_valid:
            report.append("## âœ… éªŒè¯ç»“æœï¼šé€šè¿‡")
            report.append("")
            report.append("è½¬æ¢å®Œæˆåæ­£æ–‡å†…å®¹å®Œæ•´ï¼Œæ²¡æœ‰æ˜æ˜¾çš„å†…å®¹ä¸¢å¤±ã€‚")
            report.append("")
            report.append("> ğŸ’¡ **è¯´æ˜**: å°‘é‡å­—ç¬¦æ•°å·®å¼‚æ˜¯æ­£å¸¸çš„ï¼Œé€šå¸¸ç”±ä»¥ä¸‹å› ç´ é€ æˆï¼š")
            report.append("> - æ ¼å¼åŒ–å’Œæ ‡å‡†åŒ–å¤„ç†")
            report.append("> - ç©ºç™½å­—ç¬¦çš„ç»Ÿä¸€å¤„ç†")
            report.append("> - ç« èŠ‚ç»“æ„çš„é‡æ–°ç»„ç»‡")
            report.append("> - EPUBæ ¼å¼çš„æŠ€æœ¯è¦æ±‚")
        else:
            report.append("## âŒ éªŒè¯ç»“æœï¼šå¤±è´¥")
            report.append("")
            report.append("è½¬æ¢è¿‡ç¨‹ä¸­å¯èƒ½å­˜åœ¨å†…å®¹ä¸¢å¤±ï¼Œå»ºè®®æ£€æŸ¥ï¼š")
            report.append("")
            if rates['chinese_chars'] > 1.0:
                report.append("- âš ï¸ ä¸­æ–‡å­—ç¬¦ä¸¢å¤±ç‡è¶…è¿‡1%ï¼Œå¯èƒ½å­˜åœ¨ç¼–ç æˆ–è§£æé—®é¢˜")
            if rates['english_chars'] > 2.0:
                report.append("- âš ï¸ è‹±æ–‡å­—ç¬¦ä¸¢å¤±ç‡è¶…è¿‡2%ï¼Œå¯èƒ½å­˜åœ¨æ ¼å¼å¤„ç†é—®é¢˜")
            if rates['total_chars'] > 1.0:
                report.append("- âš ï¸ æ€»ä½“å­—ç¬¦ä¸¢å¤±ç‡è¶…è¿‡1%ï¼Œå»ºè®®æ£€æŸ¥è§£æé€»è¾‘")
            report.append("")
            report.append("### ğŸ”§ å»ºè®®çš„æ£€æŸ¥æ­¥éª¤")
            report.append("")
            report.append("1. æ£€æŸ¥åŸæ–‡ä»¶æ˜¯å¦ä½¿ç”¨äº†ç‰¹æ®Šç¼–ç ")
            report.append("2. ç¡®è®¤æ–‡ä»¶ç»“æ„æ˜¯å¦ç¬¦åˆè§£æè§„åˆ™")
            report.append("3. éªŒè¯é‡è¦ç« èŠ‚å†…å®¹æ˜¯å¦å®Œæ•´")
            report.append("4. æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šæ ¼å¼å¯¼è‡´è§£æé”™è¯¯")
        
        report.append("")
        
        # å·®å¼‚åˆ†æè¯¦æƒ…è¡¨æ ¼
        report.append("## ğŸ” å­—æ•°å˜åŒ–åŸå› åˆ†æ")
        report.append("")
        
        if analysis:
            report.append("| ç±»å‹ | å˜åŒ–åŸå›  | å…³æ³¨ç¨‹åº¦ |")
            report.append("|------|----------|----------|")
            
            if 'chinese_reason' in analysis:
                report.append(f"| ä¸­æ–‡å­—ç¬¦ | {analysis['chinese_reason']} | {analysis['chinese_concern']} |")
            
            if 'english_reason' in analysis:
                report.append(f"| è‹±æ–‡å­—ç¬¦ | {analysis['english_reason']} | {analysis['english_concern']} |")
            
            if 'punctuation_reason' in analysis:
                report.append(f"| æ ‡ç‚¹ç¬¦å· | {analysis['punctuation_reason']} | {analysis['punctuation_concern']} |")
            
            if 'overall_reason' in analysis:
                report.append(f"| **æ€»ä½“è¯„ä¼°** | **{analysis['overall_reason']}** | **{analysis['overall_concern']}** |")
        
        report.append("")
        
        return "\n".join(report)


def validate_conversion_integrity(original_content: str, volumes: List[Volume]) -> Tuple[bool, str]:
    """
    éªŒè¯txtè½¬epubçš„å†…å®¹å®Œæ•´æ€§
    
    :param original_content: åŸå§‹txtæ–‡ä»¶å†…å®¹
    :param volumes: è½¬æ¢åçš„å·ç»“æ„
    :return: (æ˜¯å¦é€šè¿‡éªŒè¯, éªŒè¯æŠ¥å‘Š)
    """
    validator = WordCountValidator()
    
    # åˆ†æåŸå§‹å†…å®¹
    validator.analyze_original_content(original_content)
    
    # åˆ†æè½¬æ¢åå†…å®¹
    validator.analyze_converted_content(volumes)
    
    # ç”ŸæˆéªŒè¯æŠ¥å‘Š
    report = validator.generate_validation_report()
    
    # è·å–éªŒè¯ç»“æœ
    is_valid, _ = validator.compare_content()
    
    return is_valid, report
